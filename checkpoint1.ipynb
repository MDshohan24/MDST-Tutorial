{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrMkwVkq6B0p"
      },
      "source": [
        "# Checkpoint 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTQix8E56B0q"
      },
      "source": [
        "Reminder:\n",
        "\n",
        "- You are being evaluated for completion and effort in this checkpoint.\n",
        "- Avoid manual labor / hard coding as much as possible, everything we've taught you so far are meant to simplify and automate your process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zLtyUnZ6B0r"
      },
      "source": [
        "We will be working with the same `states_edu.csv` that you should already be familiar with from the tutorial.\n",
        "\n",
        "We investigated Grade 8 reading score in the tutorial. For this checkpoint, you are asked to investigate another test. Here's an overview:\n",
        "\n",
        "* Choose a specific response variable to focus on\n",
        ">Grade 4 Math, Grade 4 Reading, Grade 8 Math\n",
        "* Pick or create features to use\n",
        ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
        "* Explore the data as it relates to that test\n",
        ">Create at least 2 visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
        "* Create training and testing data\n",
        ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
        "* Train a ML model to predict outcome\n",
        ">Define what you want to predict, and pick a model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a>).\n",
        "\n",
        "\n",
        "Include comments throughout your code! Every cleanup and preprocessing task should be documented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I04hN1mO6B0r"
      },
      "source": [
        "<h2> Data Cleanup </h2>\n",
        "\n",
        "Import `numpy`, `pandas`, and `matplotlib`.\n",
        "\n",
        "(Feel free to import other libraries!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SPiXUZ-m6B0s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_5ZCjTr6B0s"
      },
      "source": [
        "*Load* in the \"states_edu.csv\" dataset and take a look at the head of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "DFp3vbaf6B0s",
        "outputId": "69950b91-938c-47b6-8b9a-0e4c9759ce0d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../data/states_edu.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-041619b77a58>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/states_edu.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/states_edu.csv'"
          ]
        }
      ],
      "source": [
        "#Cannot visualize data frame, colab does not seem to let pandas work\n",
        "# says FileNotFoundError, will be attempting tutorial on what I *would* do if I could see data\n",
        "df = pd.read_csv('../data/states_edu.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9ChOPc6B0s"
      },
      "source": [
        "You should always familiarize yourself with what each column in the dataframe represents. Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p77rdUPl6B0t"
      },
      "source": [
        "Use this space to rename columns, deal with missing data, etc. _(optional)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU7bIB336B0t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFRwC56b6B0t"
      },
      "source": [
        "<h2>Exploratory Data Analysis (EDA) </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkc_xr1J6B0u"
      },
      "source": [
        "Chosen one of Grade 4 Reading, Grade 4 Math, or Grade 8 Math to focus on: *ENTER YOUR CHOICE HERE*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-dgFd3t6B0u"
      },
      "source": [
        "[link text](https://)How many years of data are logged in our dataset?\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FvXfZDC6B0u"
      },
      "outputs": [],
      "source": [
        "df['Year'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN13AgTd6B0u"
      },
      "source": [
        "Let's compare Michigan to Ohio. Which state has the higher average across all\n",
        "years in the test you chose?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQiIp5246B0u"
      },
      "outputs": [],
      "source": [
        "\n",
        "    michigan_data = df[df['State'] == 'Michigan']\n",
        "    ohio_data = df[df['State'] == 'Ohio']\n",
        "    michigan_avg = michigan_data['TestScore'].mean()\n",
        "    ohio_avg = ohio_data['TestScore'].mean()\n",
        "    max(michigan_avg,ohio_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIOvt2rK6B0u"
      },
      "source": [
        "Find the average for your chosen test across all states in 2019"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54Av0yEQ6B0u"
      },
      "outputs": [],
      "source": [
        "df[\"GRADES_4_G\"].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPxF4S3s6B0u"
      },
      "source": [
        "For each state, find a maximum value for your chosen test score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCk7ChFd6B0v"
      },
      "outputs": [],
      "source": [
        "df.groupby('State')['TestScore'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ5iCuOh6B0v"
      },
      "source": [
        "*Refer to the `Grouping and Aggregating` section in Tutorial 0 if you are stuck."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScuMGw4F6B0v"
      },
      "source": [
        "<h2> Feature Engineering </h2>\n",
        "\n",
        "After exploring the data, you can choose to modify features that you would use to predict the performance of the students on your chosen response variable.\n",
        "\n",
        "You can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
        "\n",
        "Use this space to modify or create features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_07n6OxM6B0v"
      },
      "outputs": [],
      "source": [
        "#Unable to do, due to issues with colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPN8UKHp6B0v"
      },
      "source": [
        "Feature engineering justification: **<BRIEFLY DESCRIBE WHY YOU MADE THE CHANGES THAT YOU DID\\>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiIhZpsJ6B0v"
      },
      "source": [
        "<h2>Visualization</h2>\n",
        "\n",
        "Investigate the relationship between your chosen response variable and at least two predictors using visualizations. Write down your observations.\n",
        "\n",
        "**Visualization 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0J-syQk6B0v"
      },
      "outputs": [],
      "source": [
        "#Unable to do, due to issues with colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfBAR2HM6B0v"
      },
      "source": [
        "**<CAPTION FOR VIZ 1>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAN1v6K06B0w"
      },
      "source": [
        "**Visualization 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25GtxlbD6B0w"
      },
      "outputs": [],
      "source": [
        "#Unable to do, due to issues with colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqfHt_Da6B0w"
      },
      "source": [
        "**<CAPTION FOR VIZ 2>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3kwuCrR6B0w"
      },
      "source": [
        "<h2> Data Creation </h2>\n",
        "\n",
        "_Use this space to create train/test data_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wy6Qe3g6B0x"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs1Y0bBi6B0x"
      },
      "outputs": [],
      "source": [
        "# X =\n",
        "# y ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ppptejb6B0x"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#      X, y, test_size=, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF9dLlsl6B0x"
      },
      "source": [
        "<h2> Prediction </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqhtpbNH6B0x"
      },
      "source": [
        "ML Models [Resource](https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I75iH2na6B0x"
      },
      "outputs": [],
      "source": [
        "# import your sklearn class here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DQvPHMa6B0y"
      },
      "outputs": [],
      "source": [
        "# create your model here\n",
        "# model ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wn0uaUQ26B0y"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sryOCP_n6B0y"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCAvWcMb6B0y"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_F1GDBA6B0y"
      },
      "source": [
        "Choose some metrics to evaluate the performance of your model, some of them are mentioned in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouSAdk686B0z"
      },
      "outputs": [],
      "source": [
        "#Unable to do, due to issues with colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqMAZ4-Z6B0z"
      },
      "source": [
        "We have copied over the graphs that visualize the model's performance on the training and testing set.\n",
        "\n",
        "Change `col_name` and modify the call to `plt.ylabel()` to isolate how a single predictor affects the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NqUv9zvY6B0z"
      },
      "outputs": [],
      "source": [
        "# plt.ylabel() = 'COLUMN NAME OF ONE PREDICTOR'\n",
        "\n",
        "# f = plt.figure(figsize=(12,6))\n",
        "# plt.scatter(X_train[plt.ylabel()], y_train, color = \"red\")\n",
        "# plt.scatter(X_train[plt.ylabel()], model.predict(X_train), color = \"green\")\n",
        "\n",
        "# plt.legend(['True Training','Predicted Training'])\n",
        "# plt.xlabel(col_name)\n",
        "# plt.ylabel('NAME OF THE PREDICTOR')\n",
        "# plt.title(\"Model Behavior On Training Set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mjm_gCkn6B0z"
      },
      "outputs": [],
      "source": [
        "# plt.ylabel() = 'COLUMN NAME OF ONE PREDICTOR\"\n",
        "\n",
        "# f = plt.figure(figsize=(12,6))\n",
        "# plt.scatter(X_test[plt.ylabel()], y_test, color = \"blue\")\n",
        "# plt.scatter(X_test[plt.ylabel()], model.predict(X_test), color = \"black\")\n",
        "\n",
        "# plt.legend(['True testing','Predicted testing'])\n",
        "# plt.xlabel(plt.ylabel())\n",
        "# plt.ylabel('NAME OF THE PREDICTOR')\n",
        "# plt.title(\"Model Behavior on Testing Set\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6cf8df3ff69f85f626faf55c10df6fe2cb9d1236b4dc73844ee4dc01369c2c99"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}